{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Forecasting Webservice Deployment - Custom Script\n",
    "---\n",
    "\n",
    "In this notebook we deploy multiple webservices to forecast sales in real-time with the models we trained in the last step.\n",
    "\n",
    "Models are grouped based on their tags and each group is deployed together to the same webservice. You can customize your grouping strategy by simply playing with the model tags. \n",
    "\n",
    "### Prerequisites\n",
    "At this point, you should have already:\n",
    "\n",
    "1. Created your AML Workspace using the [00_Setup_AML_Workspace notebook](../00_Setup_AML_Workspace.ipynb)\n",
    "2. Run [01_Data_Preparation.ipynb](../01_Data_Preparation.ipynb) to setup your compute and create the dataset\n",
    "3. Run [02_CustomScript_Training_Pipeline.ipynb](02_CustomScript_Training_Pipeline.ipynb) to train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Connect to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "print('Workspace Name: ' + ws.name, \n",
    "      'Azure Region: ' + ws.location, \n",
    "      'Subscription Id: ' + ws.subscription_id, \n",
    "      'Resource Group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Get models to be deployed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Get all models registered in the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "models = Model.list(ws, latest=True, expand=False, page_count=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Group models by store\n",
    "\n",
    "We will create groups of models splitting by store. Therefore, each group will contain three models, one for each of the orange juice brands, and all of them corresponding to the same store.\n",
    "\n",
    "You can change the grouping strategy by modifying the `splitting_tags` variable below and specifying the names of the tags you want to use for splitting. If you leave it empty all the models will be deployed into a single webservice.\n",
    "\n",
    "To create custom tags, include them in the dataset, add their names as part of the `tags_columns` setting in the settings file of the [training script](../../scripts/customscript/train.py) and run the training again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_tags = ['Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_models = {}\n",
    "for m in models:\n",
    "    \n",
    "    if m.tags['ModelType'] == '_meta_':\n",
    "        continue\n",
    "    \n",
    "    group_name = '/'.join([m.tags[t] for t in splitting_tags]) if splitting_tags else 'allmodels'\n",
    "    group = grouped_models.setdefault(group_name, [])\n",
    "    group.append(m)\n",
    "    \n",
    "print(f'{len(grouped_models)} group(s) created. Names: {list(grouped_models.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 3.0 Configure deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 3.1 Define inference environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "forecast_env = Environment(name=\"many_models_environment\")\n",
    "forecast_conda_deps = CondaDependencies.create(pip_packages=['azureml-defaults', 'sklearn'])\n",
    "forecast_env.python.conda_dependencies = forecast_conda_deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define inference configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    source_directory='../../scripts/customscript/',\n",
    "    entry_script='model_webservice.py',\n",
    "    environment=forecast_env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 [Option A] Define deploy configuration using ACI (dev/test)\n",
    "\n",
    "Use this option to deploy the models to Azure Container Instances, indicated for dev/test environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_type = 'aci'\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "deployment_target = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 [Option B] Define deploy configuration using AKS (production)\n",
    "\n",
    "Use this option to deploy the models to Azure Kubernetes Services, indicated for production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_target_name = 'manymodels-aks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AksCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "try:\n",
    "    aks_target = AksCompute(ws, aks_target_name)\n",
    "    print('AKS cluster already attached. Skip the optional step below and jump to \"Configure AKS\"')\n",
    "except ComputeTargetException:\n",
    "    print('AKS cluster not attached yet. Run the optional step below to do so')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Optional] Attach AKS cluster\n",
    "\n",
    "Attach existing AKS cluster as Compute Target in Azure Machine Learning. This needs to be run only the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_resource_name = '<my-aks-name>'\n",
    "aks_resource_group = '<my-aks-resource-group>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "attach_config = AksCompute.attach_configuration(\n",
    "    resource_group=aks_resource_group,\n",
    "    cluster_name=aks_resource_name\n",
    ")\n",
    "\n",
    "aks_target = ComputeTarget.attach(ws, aks_target_name, attach_config)\n",
    "aks_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "deployment_type = 'aks'\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "deployment_target = aks_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Deploy the models\n",
    "\n",
    "We will now deploy one webservice for each of the groups of models. Deployment takes some minutes to complete, so we'll request all of them and then wait for them to finish.\n",
    "\n",
    "We will store the information on a python dictionary that we'll use later on to find the corresponding webservice for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deployments = []\n",
    "for group_name, group_models in grouped_models.items():\n",
    "    \n",
    "    service_name = '{prefix}manymodels-{group}'.format(\n",
    "        prefix='test-' if deployment_type == 'aci' else '',\n",
    "        group=group_name\n",
    "    ).lower()\n",
    "    \n",
    "    print('Launching deployment of {}...'.format(service_name))\n",
    "    service = Model.deploy(\n",
    "        workspace=ws,\n",
    "        name=service_name,\n",
    "        models=group_models,\n",
    "        inference_config=inference_config,\n",
    "        deployment_config=deployment_config,\n",
    "        deployment_target=deployment_target,\n",
    "        overwrite=True\n",
    "    )\n",
    "    print('Deployment of {} started'.format(service_name))\n",
    "    \n",
    "    deployments.append({ 'service': service, 'group': group_name, 'models': group_models })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_deployed = {}\n",
    "for deployment in deployments:\n",
    "    \n",
    "    service = deployment['service']\n",
    "    print('Waiting for deployment of {} to finish...'.format(service.name))\n",
    "    service.wait_for_deployment(show_output=True)\n",
    "    if service.state != 'Healthy':\n",
    "        print('DEPLOYMENT FAILED FOR SERVICE {}'.format(service.name))\n",
    "    \n",
    "    service_info = {\n",
    "        'webservice': service.name,\n",
    "        'state': service.state,\n",
    "        'endpoint': service.scoring_uri if service.state == 'Healthy' else None,\n",
    "        'key': service.get_keys()[0] if service.auth_enabled and service.state == 'Healthy' else None\n",
    "    }\n",
    "\n",
    "    # Store deployment info for each deployed model\n",
    "    for m in deployment['models']:\n",
    "        models_deployed[m.name] = {\n",
    "            'version': m.version,\n",
    "            'group': deployment['group'],\n",
    "            **service_info\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test the webservices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query for multiple models into the same request, but all of them need to be from the same store, as each endpoint only contains models corresponding to one particular store.\n",
    "\n",
    "The webservice deployed needs some data to generate the prediction:\n",
    "- Data used for identifying the model (store, brand, model type)\n",
    "- The timestamp where forecasting should start, the number of horizons we want to predict and the frequency of the forecasts\n",
    "- The past values of the target variable (Quantity) to generate the lags\n",
    "- The future value of the external regressors (Price, Advert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store1, brand1 = ('1000', 'minute.maid')\n",
    "store2, brand2 = ('1000', 'tropicana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        \"id\": {\n",
    "            \"Store\": store1,\n",
    "            \"Brand\": brand1\n",
    "        },\n",
    "        \"model_type\": \"lr\",\n",
    "        \"forecast_start\": \"2020-05-21\", \"forecast_freq\": \"W-THU\", \"forecast_horizon\": 4,\n",
    "        \"data\": {\n",
    "            \"historical\": {\n",
    "                \"Quantity\": [11450, 12235, 14713]\n",
    "            },\n",
    "            \"future\": {\n",
    "                \"Price\": [2.4, 2.5, 3, 3],\n",
    "                \"Advert\": [0, 1, 1, 1]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": {\n",
    "            \"Store\": store2,\n",
    "            \"Brand\": brand2\n",
    "        },\n",
    "        \"model_type\": \"lr\",\n",
    "        \"forecast_start\": \"2020-05-21\", \"forecast_freq\": \"W-THU\", \"forecast_horizon\": 5,\n",
    "        \"data\": {\n",
    "            \"historical\": {\n",
    "                \"Quantity\": [25692, 32976, 28610]\n",
    "            },\n",
    "            \"future\": {\n",
    "                \"Price\": [1.5, 1.5, 3.1, 3.2, 3.5],\n",
    "                \"Advert\": [0, 0, 1, 1, 1]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get webservice endpoint and key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../scripts/customscript')\n",
    "from utils.models import get_model_name\n",
    "\n",
    "model_name = get_model_name('lr', {'Store': store1, 'Brand': brand1})\n",
    "\n",
    "try:\n",
    "    url = models_deployed[model_name]['endpoint']\n",
    "    key = models_deployed[model_name]['key']\n",
    "except KeyError as e:\n",
    "    raise ValueError(f'Model for store {store1} and brand {brand1} has not been deployed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send request to model webservice to get forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "request_headers = {'Content-Type': 'application/json'}\n",
    "if key:\n",
    "    request_headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "response = requests.post(url, json=test_data, headers=request_headers)\n",
    "print(response.status_code)\n",
    "\n",
    "if response.ok:\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Group all models into a single routing endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now group all the services into a single entry point, so that we don't have to handle each endpoint separately. \n",
    "For that, we'll register the `models_deployed` object as a model, and deploy it as a webservice. This webservice will receive the incoming requests and route them to the appropiate model service, acting as the unique entry point for outside requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Register endpoints dict as an AML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "artifact_path = 'models_deployed.json'\n",
    "with open(artifact_path, 'w') as f:\n",
    "    json.dump(models_deployed, f, indent=4)\n",
    "\n",
    "dep_model = Model.register(\n",
    "    workspace=ws, \n",
    "    model_path=artifact_path,\n",
    "    model_name='deployed_models_info',\n",
    "    tags={'ModelType': '_meta_'},\n",
    "    description='Dictionary of the service endpoint where each model is deployed'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Deploy routing webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "routing_env = Environment(name=\"many_models_routing_environment\")\n",
    "routing_env_deps = CondaDependencies.create(pip_packages=['azureml-defaults'])\n",
    "routing_env.python.conda_dependencies = routing_env_deps\n",
    "\n",
    "routing_infconfig = InferenceConfig(\n",
    "    source_directory='../../scripts/customscript/',\n",
    "    entry_script='routing_webservice.py',\n",
    "    environment=routing_env\n",
    ")\n",
    "\n",
    "# Reuse deployment config with lower capacity\n",
    "deployment_config.cpu_cores = 0.1\n",
    "deployment_config.memory_gb = 0.5\n",
    "\n",
    "routing_service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name='routing-manymodels',\n",
    "    models=[dep_model],\n",
    "    inference_config=routing_infconfig,\n",
    "    deployment_config=deployment_config,\n",
    "    deployment_target=deployment_target,\n",
    "    overwrite=True\n",
    ")\n",
    "routing_service.wait_for_deployment(show_output=True)\n",
    "\n",
    "assert routing_service.state == 'Healthy'\n",
    "\n",
    "print('Routing endpoint deployed with URL: {}'.format(routing_service.scoring_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Test the webservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new endpoint can be called with data from different stores or brands, and it will automatically route the request to the appropiate model endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store1, brand1 = ('1002', 'minute.maid')\n",
    "store2, brand2 = ('1000', 'tropicana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        \"id\": {\n",
    "            \"Store\": store1,\n",
    "            \"Brand\": brand1\n",
    "        },\n",
    "        \"model_type\": \"lr\",\n",
    "        \"forecast_start\": \"2020-05-21\", \"forecast_freq\": \"W-THU\", \"forecast_horizon\": 5,\n",
    "        \"data\": {\n",
    "            \"historical\": {\n",
    "                \"Quantity\": [11450, 12235, 14713]\n",
    "            },\n",
    "            \"future\": {\n",
    "                \"Price\": [2.4, 2.5, 3, 3, 3],\n",
    "                \"Advert\": [0, 1, 1, 1, 1]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": {\n",
    "            \"Store\": store2,\n",
    "            \"Brand\": brand2\n",
    "        },\n",
    "        \"model_type\": \"lr\",\n",
    "        \"forecast_start\": \"2020-05-21\", \"forecast_freq\": \"W-THU\", \"forecast_horizon\": 3,\n",
    "        \"data\": {\n",
    "            \"historical\": {\n",
    "                \"Quantity\": [21450, 25291, 24910]\n",
    "            },\n",
    "            \"future\": {\n",
    "                \"Price\": [5.2, 4.3, 5],\n",
    "                \"Advert\": [0, 0, 0]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": {\n",
    "            \"Store\": store1,\n",
    "            \"Brand\": brand2\n",
    "        },\n",
    "        \"model_type\": \"lr\",\n",
    "        \"forecast_start\": \"2020-05-21\", \"forecast_freq\": \"W-THU\", \"forecast_horizon\": 10,\n",
    "        \"data\": {\n",
    "            \"historical\": {\n",
    "                \"Quantity\": [13710, 11641, 9701]\n",
    "            },\n",
    "            \"future\": {\n",
    "                \"Price\": [1.5, 2, 2, 2, 2, 1.5, 1.5, 1.5, 2, 2],\n",
    "                \"Advert\": [0, 0, 0, 0, 1, 1, 1, 1, 0, 0]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": {\n",
    "            \"Store\": store2,\n",
    "            \"Brand\": brand1\n",
    "        },\n",
    "        \"model_type\": \"lr\",\n",
    "        \"forecast_start\": \"2020-05-21\", \"forecast_freq\": \"W-THU\", \"forecast_horizon\": 4,\n",
    "        \"data\": {\n",
    "            \"historical\": {\n",
    "                \"Quantity\": [8192, 7103, 11710]\n",
    "            },\n",
    "            \"future\": {\n",
    "                \"Price\": [3.5, 3.5, 4, 4],\n",
    "                \"Advert\": [0, 0, 1, 1]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = routing_service.scoring_uri\n",
    "\n",
    "request_headers = {'Content-Type': 'application/json'}\n",
    "if routing_service.auth_enabled:\n",
    "    keys = routing_service.get_keys()\n",
    "    request_headers['Authorization'] = 'Bearer {}'.format(keys[0])\n",
    "\n",
    "response = requests.post(url, json=test_data, headers=request_headers)\n",
    "print(response.status_code)\n",
    "\n",
    "if response.ok:\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
