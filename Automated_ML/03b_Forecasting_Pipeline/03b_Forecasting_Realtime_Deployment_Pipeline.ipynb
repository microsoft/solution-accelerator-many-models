{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/manymodels/03_Forecasting/03_Forecasting_Pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Forecasting Webservice Deployment\n",
    "---\n",
    "\n",
    "In this notebook we deploy multiple webservices to forecast sales in real-time with the models we trained in the last step.\n",
    "\n",
    "Models are grouped based on their tags and each group is deployed together to the same webservice. You can customize your grouping strategy by simply playing with the model tags. \n",
    "\n",
    "### Prerequisites \n",
    "At this point, you should have already: \n",
    "1. Created your AML Workspace\n",
    "2. Run 01_Data_Preparation.ipynb to register the datasets\n",
    "3. Run 02_Training_Pipeline.ipynb to train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Connect to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore\n",
    "import pandas as pd\n",
    "\n",
    "# set up workspace\n",
    "ws= Workspace.from_config() \n",
    "\n",
    "# Take a look at Workspace\n",
    "ws.get_details()\n",
    "\n",
    "# set up datastores\n",
    "dstore = ws.get_default_datastore()\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Default datastore name'] = dstore.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Get models to be deployed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Get models registered in the workspace that had been trained by a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "runid =  '<update pipeline run id>' # update the pipeline run \n",
    "tags = [['ModelType', 'AutoML'], ['RunId', runid]]\n",
    "\n",
    "models = Model.list(ws, tags=tags, latest=True)\n",
    "print('Got '+str(len(models))+' models from the workspace.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Group models by store\n",
    "\n",
    "We will group the models by store. Therefore, each group will contain three models, one for each of the orange juice brands, and all of them corresponding to the same store.\n",
    "\n",
    "You can change the grouping strategy by modifying the `grouping_tags` variable below and specifying the names of the tags you want to use for grouping. For convenience, we have created two additional grouping tags you can use:\n",
    "- `StoreGroup10`: groups stores 10 by 10\n",
    "- `StoreGroup100`: groups stores 100 by 100\n",
    "\n",
    "To create custom tags, modify the `tags_dict` object in the [training script](scripts/train.py) and run the training again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_tags = ['Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_models = {}\n",
    "for m in models:\n",
    "    \n",
    "    if m.tags['ModelType'] == '_meta_':\n",
    "        continue\n",
    "    \n",
    "    group_name = '/'.join([m.tags[t] for t in grouping_tags])\n",
    "    group = grouped_models.setdefault(group_name, [])\n",
    "    group.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 3.0 Configure deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 3.1 Define inference environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.helper import get_automl_environment\n",
    "forecast_env = get_automl_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define inference configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    entry_script='forecast_webservice.py',\n",
    "    source_directory='./scripts',\n",
    "    environment=forecast_env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 [Option A] Define deploy configuration using ACI (dev/test)\n",
    "\n",
    "Use this option to deploy the models to Azure Container Instances, indicated for dev/test environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_type = 'aci'\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "deployment_target = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 [Option B] Define deploy configuration using AKS (production)\n",
    "\n",
    "Use this option to deploy the models to Azure Kubernetes Services, indicated for production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_target_name = 'manymodels-aks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AksCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "try:\n",
    "    aks_target = AksCompute(ws, aks_target_name)\n",
    "    print('AKS cluster already attached. Skip the optional step below and jump to \"Configure AKS\"')\n",
    "except ComputeTargetException:\n",
    "    print('AKS cluster not attached yet. Run the optional step below to do so')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Optional] Attach AKS cluster\n",
    "\n",
    "Attach existing AKS cluster as Compute Target in Azure Machine Learning. This needs to be run only the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_resource_name = '<my-aks-name>'\n",
    "aks_resource_group = '<my-aks-resource-group>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "attach_config = AksCompute.attach_configuration(\n",
    "    resource_group=aks_resource_group,\n",
    "    cluster_name=aks_resource_name\n",
    ")\n",
    "\n",
    "aks_target = ComputeTarget.attach(ws, aks_target_name, attach_config)\n",
    "aks_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "deployment_type = 'aks'\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "deployment_target = aks_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Deploy the models\n",
    "\n",
    "We will now deploy one webservice for each of the groups of models. Deployment takes some minutes to complete, so we'll request all of them and then wait for them to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployments = []\n",
    "for group_name, group_models in grouped_models.items():\n",
    "    \n",
    "    service_name = '{prefix}manymodels-{group}'.format(\n",
    "        prefix='test-' if deployment_type == 'aci' else '',\n",
    "        group=group_name\n",
    "    ).lower()\n",
    "    \n",
    "    print('Launching deployment of {}...'.format(service_name))\n",
    "    service = Model.deploy(\n",
    "        workspace=ws,\n",
    "        name=service_name,\n",
    "        models=group_models,\n",
    "        inference_config=inference_config,\n",
    "        deployment_config=deployment_config,\n",
    "        deployment_target=deployment_target,\n",
    "        overwrite=True\n",
    "    )\n",
    "    print('Deployment of {} started'.format(service_name))\n",
    "    \n",
    "    deployments.append({ 'service': service, 'group': group_name, 'models': group_models })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_deployed = {}\n",
    "for deployment in deployments:\n",
    "    \n",
    "    service = deployment['service']\n",
    "    print('Waiting for deployment of {} to finish...'.format(service.name))\n",
    "    service.wait_for_deployment(show_output=True)\n",
    "    if service.state != 'Healthy':\n",
    "        print('DEPLOYMENT FAILED FOR SERVICE {}'.format(service.name))\n",
    "    \n",
    "    service_info = {\n",
    "        'webservice': service.name,\n",
    "        'state': service.state,\n",
    "        'endpoint': service.scoring_uri if service.state == 'Healthy' else None,\n",
    "        'key': service.get_keys()[0] if service.auth_enabled and service.state == 'Healthy' else None\n",
    "    }\n",
    "\n",
    "    # Store deployment info for each deployed model\n",
    "    for m in deployment['models']:\n",
    "        models_deployed[m.name] = {\n",
    "            'version': m.version,\n",
    "            'group': deployment['group'],\n",
    "            **service_info\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test the webservices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query for multiple models into the same request, but all of them need to be from the same store, as each endpoint only contains models corresponding to one particular store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "# Please change the following to point to your own blob container and pass in account_key\n",
    "blob_datastore_name = \"automl_many_models\"\n",
    "container_name = \"automl-sample-notebook-data\"\n",
    "account_name = \"automlsamplenotebookdata\"\n",
    "\n",
    "oj_datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                       datastore_name=blob_datastore_name, \n",
    "                                                       container_name=container_name,\n",
    "                                                       account_name=account_name,\n",
    "                                                       create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "inference_name_small = 'oj_inference_small'\n",
    "\n",
    "inference_ds_small = Dataset.Tabular.from_delimited_files(path=oj_datastore.path(inference_name_small + '/'), validate=False)\n",
    "all_df = inference_ds_small.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.helper import get_model_name\n",
    "store = 1002\n",
    "brand = 'dominicks'\n",
    "tags_dict = {'store':store, 'brand': brand}\n",
    "model_name = get_model_name(tags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominicks_test_data = all_df.loc[(all_df['Store']==store) & (all_df['Brand']==brand)]\n",
    "print(dominicks_test_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominicks_test_data_json = dominicks_test_data[:].to_json(orient='records', date_format='iso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [{\n",
    "        \"group_column_names\": ['Store', 'Brand'], # This is the same list that is passed in the training script\n",
    "        \"time_column_name\": \"WeekStarting\", # This is the same value for time_column_name that is passed in the training script\n",
    "        \"data\": dominicks_test_data_json\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "try:\n",
    "    url = models_deployed[model_name]['endpoint']\n",
    "    key = models_deployed[model_name]['key']    \n",
    "except KeyError as e:\n",
    "    raise ValueError(f'Model for store {store} and brand {brand} has not been deployed')\n",
    "\n",
    "request_headers = {'Content-Type': 'application/json'}\n",
    "if key:\n",
    "    request_headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "response = requests.post(url, json=test_data, headers=request_headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Group all models into a single routing endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now group all the services into a single entry point, so that we don't have to handle each endpoint separately. \n",
    "For that, we'll register the `endpoints` object as a model, and deploy it as a webservice. This webservice will receive the incoming requests and route them to the appropiate model service, acting as the unique entry point for outside requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Register endpoints dict as an AML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(models_deployed, 'models_deployed.pkl')\n",
    "\n",
    "dep_model = Model.register(\n",
    "    workspace=ws, \n",
    "    model_path ='models_deployed.pkl', \n",
    "    model_name='deployed_models_info',\n",
    "    tags={'ModelType': '_meta_'},\n",
    "    description='Dictionary of the service endpoint where each model is deployed'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Deploy routing webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "routing_env = Environment(name=\"many_models_routing_environment\")\n",
    "routing_env_deps = CondaDependencies.create(pip_packages=['azureml-defaults', 'joblib'])\n",
    "routing_env.python.conda_dependencies = routing_env_deps\n",
    "\n",
    "routing_infconfig = InferenceConfig(\n",
    "    entry_script='routing_webservice.py',\n",
    "    source_directory='./scripts',\n",
    "    environment=routing_env\n",
    ")\n",
    "\n",
    "# Reuse deployment config with lower capacity\n",
    "deployment_config.cpu_cores = 0.1\n",
    "deployment_config.memory_gb = 0.5\n",
    "\n",
    "routing_service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name='routing-manymodels',\n",
    "    models=[dep_model],\n",
    "    inference_config=routing_infconfig,\n",
    "    deployment_config=deployment_config,\n",
    "    deployment_target=deployment_target,\n",
    "    overwrite=True\n",
    ")\n",
    "routing_service.wait_for_deployment(show_output=True)\n",
    "\n",
    "assert routing_service.state == 'Healthy'\n",
    "\n",
    "print('Routing endpoint deployed with URL: {}'.format(routing_service.scoring_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Test the webservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new endpoint can be called with data from different stores or brands, and it will automatically route the request to the appropiate model endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "url = routing_service.scoring_uri\n",
    "\n",
    "request_headers = {'Content-Type': 'application/json'}\n",
    "if routing_service.auth_enabled:\n",
    "    keys = routing_service.get_keys()\n",
    "    request_headers['Authorization'] = 'Bearer {}'.format(keys[0])\n",
    "\n",
    "response = requests.post(url, json=test_data, headers=request_headers)\n",
    "response.json()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "deeptim"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
